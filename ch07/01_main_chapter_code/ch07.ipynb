{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 7:Finetuning To Follow Instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.0\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.1\n",
      "tqdm version: 4.67.1\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version \n",
    "pkgs = [\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries : 1100\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import os \n",
    "import urllib \n",
    "\n",
    "def download_and_load_file(file_path ,url):\n",
    "  if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "      text_data = response.read().decode(\"utf-8\")\n",
    "    with open(file_path , \"w\" , encoding=\"utf-8\") as file:\n",
    "      file.write(text_data)\n",
    "  with open(file_path , \"r\" , encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "  return data \n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path , url)\n",
    "print(\"Number of entries :\" , len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exmple Entry :\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n",
      "Exmple Entry :\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print (\"Exmple Entry :\\n\" ,data[50])\n",
    "print (\"Exmple Entry :\\n\" ,data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2  Preparing dataset for supervised instruction fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "  instruction_text = (\n",
    "    f\"Below is an instruction that describes a task. \"\n",
    "    f\"Write a response that appropriately completes the request.\"\n",
    "    f\"\\n\\\\n### Instruction:\\\\n{entry['instruction']}\"\n",
    "  )\n",
    "  \n",
    "  input_text = (f\"\\n\\\\n### Input:\\\\n {entry['input']}\" if entry[\"input\"] else \"\")\n",
    "  return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\\n### Instruction:\\nIdentify the correct spelling of the following word.\n",
      "\\n### Input:\\n Ocassion\n",
      "\\n### Response:\\nThe correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\\\n### Response:\\\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\\n### Instruction:\\nWhat is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set length : 935\n",
      "test set length : 110\n",
      "val set length : 55\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:] \n",
    "\n",
    "print(f\"train set length : {len(train_data)}\")\n",
    "print(f\"test set length : {len(test_data)}\")\n",
    "print(f\"val set length : {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Organizing data into training batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "  def __init__(self, data , tokenizer):\n",
    "    self.data = data\n",
    "    self.encoded_texts = []\n",
    "    for entry in data :\n",
    "      instruction_plus_input = format_input(entry)\n",
    "      response_text = f\"\\n\\\\n### Response:\\\\n{entry['output']}\"\n",
    "      full_text = instruction_plus_input + response_text \n",
    "      self.encoded_texts.append(\n",
    "        tokenizer.encode(full_text)\n",
    "      )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "      return self.encoded_texts[index]\n",
    "    def __len__(self):\n",
    "      return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
