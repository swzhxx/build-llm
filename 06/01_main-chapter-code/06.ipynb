{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter6 :Finetuning for Text Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.0\n",
      "numpy version: 2.0.1\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.1\n",
      "tensorflow version: 2.18.0\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from importlib.metadata import version \n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to prevent certain cells from being executed twice\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "executed_cells = set()\n",
    "\n",
    "@register_line_cell_magic\n",
    "def run_once(line, cell):\n",
    "    if line not in executed_cells:\n",
    "        get_ipython().run_cell(cell)\n",
    "        executed_cells.add(line)\n",
    "    else:\n",
    "        print(f\"Cell '{line}' has already been executed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request \n",
    "import zipfile \n",
    "from pathlib import Path \n",
    "import os\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url , zip_path , extracted_path , data_file_path):\n",
    "  if data_file_path.exists():\n",
    "    print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "    return\n",
    "  with urllib.request.urlopen(url) as response:\n",
    "    with open(zip_path , \"wb\") as out_file:\n",
    "      out_file.write(response.read())\n",
    "    print(\"downloaded\")\n",
    "  with zipfile.ZipFile(zip_path , \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extracted_path)\n",
    "  original_file_path = Path(extracted_path) / \"SMSSpamCollection\" \n",
    "  os.rename(original_file_path , data_file_path)\n",
    "  print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url , zip_path ,extracted_path , data_file_path)    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(data_file_path , sep=\"\\t\" , header=None , names=[\"Label\" , \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_spam , 747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Label  Text                                                                                                                                                               \n",
       "ham    Sorry, I'll call later                                                                                                                                                 7\n",
       "spam   Please call our customer service representative on FREEPHONE 0808 145 4742 between 9am-11pm as you have WON a guaranteed £1000 cash or £5000 prize!                    4\n",
       "ham    Just sleeping..and surfing                                                                                                                                             3\n",
       "spam   I don't know u and u don't know me. Send CHAT to 86688 now and let's find each other! Only 150p/Msg rcvd. HG/Suite342/2Lands/Row/W1J6HL LDN. 18 years or over.         3\n",
       "       Camera - You are awarded a SiPix Digital Camera! call 09061221066 fromm landline. Delivery within 28 days.                                                             3\n",
       "                                                                                                                                                                             ..\n",
       "       important information 4 orange user 0789xxxxxxx. today is your lucky day!2find out why log onto http://www.urawinner.com THERE'S A FANTASTIC SURPRISE AWAITING YOU!    1\n",
       "       it to 80488. Your 500 free text messages are valid until 31 December 2005.                                                                                             1\n",
       "       lyricalladie(21/F) is inviting you to be her friend. Reply YES-910 or NO-910. See her: www.SMS.ac/u/hmmross STOP? Send STOP FRND to 62468                              1\n",
       "       money!!! you r a lucky winner ! 2 claim your prize text money 2 88600 over £1million to give away ! ppt150x3+normal text rate box403 w1t1jy                            1\n",
       "       network operator. The service is free. For T & C's visit 80488.biz                                                                                                     1\n",
       "Name: count, Length: 1388, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "  num_spam = df[df['Label'] == \"spam\"].shape[0]\n",
    "  print(f\"num_spam , {num_spam}\")\n",
    "  ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam , random_state = 123)\n",
    "  balanced_df = pd.concat([ham_subset , df[df[\"Label\"] == \"spam\"]])\n",
    "  return balanced_df\n",
    "  \n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df['Label'] = balanced_df['Label'].map({\"ham\":0 , \"spam\":1})\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df , train_frac , validation_frac):\n",
    "  df = df.sample(frac = 1 , random_state = 123).reset_index(drop=True)\n",
    "  train_end = int(len(df) * train_frac)\n",
    "  validation_end = train_end + int(len(df) * validation_frac)\n",
    "  \n",
    "  train_df = df[:train_end]\n",
    "  validation_df = df[train_end:validation_end]\n",
    "  test_df = df[validation_end:]\n",
    "  return train_df , validation_df , test_df\n",
    "  \n",
    "  \n",
    "train_df , validation_df , test_df = random_split(balanced_df , 0.7 , 0.1)\n",
    "train_df.to_csv(\"train.csv\" , index = None)\n",
    "validation_df.to_csv(\"validation.csv\" , index = None)\n",
    "test_df.to_csv(\"test.csv\" , index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken \n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\" , allowed_special = {\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "        # Note: A more pythonic version to implement this method\n",
    "        # is the following, which is also used in the next chapter:\n",
    "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = SpamDataset(csv_file = \"train.csv\" , max_length = None , tokenizer = tokenizer)\n",
    "train_dataset.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(csv_file = \"validation.csv\" , max_length = train_dataset.max_length , tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(csv_file = \"test.csv\" , max_length = train_dataset.max_length , tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "num_workers = 0 \n",
    "batch_size = 8 \n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset , batch_size = batch_size , shuffle=True , num_workers = num_workers , drop_last= True)\n",
    "val_loader = DataLoader(dataset=val_dataset , batch_size = batch_size , num_workers = num_workers , drop_last = False)\n",
    "test_loader = DataLoader(dataset = test_dataset , batch_size = batch_size , num_workers = num_workers , drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Loader\") \n",
    "for input_batch , target_batch in train_loader :\n",
    "  pass \n",
    "print(\"Input batch dimensions:\" , input_batch.shape)\n",
    "print(\"Label batch dimensions\" , target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6.4 Initializing a model with pretrained weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort Moves\" \n",
    "\n",
    "BASE_CONFIG = {\n",
    "  \"vocab_size\" : 50257 , \n",
    "  \"context_length\":1024, \n",
    "  \"drop_rate\":0.0 ,\n",
    "  \"qkv_bias\":True\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2 \n",
    "from previous_chapters import GPTModel , load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (generate_text_simple , text_to_token_ids , token_ids_to_text)\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Adding a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the model ready for classification fine-tuning, we first\n",
    "#freeze the model, meaning that we make all layers\n",
    "#nontrainable:\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 2 \n",
    "model.out_head = torch.nn.Linear(in_features= BASE_CONFIG[\"emb_dim\"] , out_features=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:,-1,:] , dim = -1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"class label\" , label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader , model , device , num_batches = None):\n",
    "  model.eval() \n",
    "  correct_predictions , num_examples = 0 ,0 \n",
    "  if num_batches is None : \n",
    "    num_batches = len(data_loader)\n",
    "  else :\n",
    "    num_batches = min(num_batches , len(data_loader))\n",
    "  for i , (input_batch , target_batch) in enumerate(data_loader):\n",
    "    if i < num_batches : \n",
    "      input_batch , target_batch = input_batch.to(device) , target_batch.to(device)\n",
    "      with torch.no_grad():\n",
    "        logits = model(input_batch)[: , -1 , :]\n",
    "      predicted_labels = torch.argmax(logits , dim = -1)\n",
    "      num_examples += predicted_labels.shape[0]\n",
    "      correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "    else :\n",
    "      break\n",
    "  return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader , model , device , num_batches = None):\n",
    "  total_loss = 0. \n",
    "  if len(data_loader) == 0:\n",
    "    return float(\"nan\")\n",
    "  elif num_batches  is None:\n",
    "    num_batches = len(data_loader)\n",
    "  else:\n",
    "    num_batches = min(num_batches , len(data_loader))\n",
    "  for i ,(input_batch , target_batch) in enumerate(data_loader):\n",
    "    if i < num_batches:\n",
    "      loss = calc_loss_batch(input_batch , target_batch , model , device)\n",
    "      total_loss += loss.item()\n",
    "    else :\n",
    "      break\n",
    "  return total_loss/ num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model , train_loader ,val_loader , optimizer , device , num_epochs , eval_freq , eval_iter):\n",
    "  train_losses , val_losses , train_accs , val_accs = [],[],[],[]\n",
    "  examples_seen, global_step = 0 , -1\n",
    "  print(\"a\")\n",
    "  for epoch in range(num_epochs):\n",
    "    print(f\"epoch {epoch}\")\n",
    "    model.train()\n",
    "    \n",
    "    for input_batch , target_batch in train_loader:\n",
    "      optimizer.zero_grad()\n",
    "      loss = calc_loss_batch(input_batch , target_batch , model , device)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      examples_seen += input_batch.shape[0]\n",
    "      global_step += 1 \n",
    "      # print(f\"global_step {global_step}\")\n",
    "      if global_step % eval_freq == 0: \n",
    "        train_loss , val_loss = evaluate_model(model , train_loader , val_loader , device , eval_iter)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "    \n",
    "    train_accuracy = calc_accuracy_loader(train_loader , model , device , num_batches = eval_iter)\n",
    "    val_accuracy = calc_accuracy_loader(val_loader , model , device , num_batches = eval_iter)\n",
    "    print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "    print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "    train_accs.append(train_accuracy)\n",
    "    val_accs.append(val_accuracy)\n",
    "  return train_losses , val_losses , train_accs , val_accs , examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model , train_loader , val_laoder , device , eval_iter):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader , model , device,num_batches = eval_iter)\n",
    "    val_loss  = calc_loss_loader(val_loader , model , device,num_batches = eval_iter)\n",
    "  model.train()\n",
    "  return train_loss ,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "epoch 0\n",
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "epoch 1\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "epoch 2\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "epoch 3\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "epoch 4\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 2.31 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
